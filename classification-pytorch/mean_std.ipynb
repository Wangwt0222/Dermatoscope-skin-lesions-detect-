{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10015\n",
      "normMean = [0.76608187, 0.5597207, 0.58785397]\n",
      "normStd = [0.15595692, 0.1533187, 0.17299013]\n",
      "transforms.Normalize(normMean = [0.76608187, 0.5597207, 0.58785397], normStd = [0.15595692, 0.1533187, 0.17299013])\n",
      "14.439172506332397\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import time\n",
    " \n",
    "# calculate means and std\n",
    "train_txt_path = './train_val_list.txt'\n",
    "image_path = '/media/scw4750/disk/test/skin_detect/isic2018-master/task3/images/HAM10000/'\n",
    "\n",
    "img_dir = glob.glob(image_path+\"*.jpg\")\n",
    "print(len(img_dir))\n",
    "\n",
    "CNum = 100      # 挑选多少图片进行计算\n",
    " \n",
    "img_h, img_w = 600, 450\n",
    "imgs = np.zeros([img_w, img_h, 3, 1])\n",
    "means, stdevs = [], []\n",
    "\n",
    "start = time.time()\n",
    "for i in range(CNum):\n",
    "    img = cv2.imread(img_dir[i])\n",
    "    img = img[:, :, :, np.newaxis]\n",
    "    imgs = np.concatenate((imgs, img), axis=3)\n",
    "    \n",
    "imgs = imgs.astype(np.float32)/255.\n",
    "\n",
    "for i in range(3):\n",
    "    pixels = imgs[:,:,i,:].ravel()  # 拉成一行\n",
    "    means.append(np.mean(pixels))\n",
    "    stdevs.append(np.std(pixels))\n",
    "\n",
    "# cv2 读取的图像格式为BGR，PIL/Skimage读取到的都是RGB不用转\n",
    "means.reverse() # BGR --> RGB\n",
    "stdevs.reverse()\n",
    " \n",
    "print(\"normMean = {}\".format(means))\n",
    "print(\"normStd = {}\".format(stdevs))\n",
    "print('transforms.Normalize(normMean = {}, normStd = {})'.format(means, stdevs))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices to use: 1\n",
      "Train\n",
      "(8009,)\n",
      "val\n",
      "(2006,)\n",
      "Current class weights [ 9.019144   1.5012184 19.7266    29.553505   8.938616  84.30526\n",
      " 67.87288  ]\n",
      "[0.7811761  0.5264199  0.54028153] [0.13406543 0.17649162 0.1900084 ]\n",
      "[0.754263   0.50416595 0.5183167 ] [0.13232674 0.15433034 0.1807971 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import *\n",
    "import pretrainedmodels\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import logging\n",
    "import errno\n",
    "import random\n",
    "import pickle\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from multiprocessing import Process\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import math\n",
    "from torchvision import models, transforms, utils\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from decimal import Decimal\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "#填写cuda使用范围[0,1,2,3]\n",
    "numGPUs = [1]\n",
    "cuda_str = \"\"\n",
    "for i in range(len(numGPUs)):\n",
    "    cuda_str = cuda_str + str(numGPUs[i])\n",
    "    if i is not len(numGPUs)-1:\n",
    "        cuda_str = cuda_str + \",\"\n",
    "print(\"Devices to use:\",cuda_str)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_str\n",
    "#数据类，特别重要\n",
    "class ISICdataset(Dataset):\n",
    "    def __init__(self, setInd, im_paths, labels_array, train=True):\n",
    "        self.train = train\n",
    "        self.same_sized_crop = True\n",
    "        self.full_color_distort = False\n",
    "        self.input_size = (np.int32([224, 224, 3][0]),np.int32([224, 224, 3][1]))\n",
    "        self.setMean = np.array([0, 0, 0]).astype(np.float32)\n",
    "        self.indices = setInd\n",
    "        self.im_paths = im_paths\n",
    "        self.labels_array = labels_array\n",
    "\n",
    "        if self.train:\n",
    "            if self.same_sized_crop:\n",
    "                cropping = transforms.RandomCrop(self.input_size)\n",
    "            else:\n",
    "                cropping = transforms.RandomResizedCrop(self.input_size[0])\n",
    "                # Color distortion\n",
    "            if self.full_color_distort:\n",
    "                color_distort = transforms.ColorJitter(brightness=32. / 255., saturation=0.5, contrast=0.5, hue=0.2)\n",
    "            else:\n",
    "                color_distort = transforms.ColorJitter(brightness=32. / 255., saturation=0.5)\n",
    "                # All transforms\n",
    "            self.composed = transforms.Compose([\n",
    "                cropping,\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                color_distort,\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(torch.from_numpy(self.setMean).float(),\n",
    "                                     torch.from_numpy(np.array([1., 1., 1.])).float())\n",
    "            ])\n",
    "            self.labels = labels_array[setInd, :]\n",
    "            self.im_paths = np.array(im_paths)[setInd].tolist()\n",
    "        else:\n",
    "            cropping = transforms.RandomResizedCrop(self.input_size[0])\n",
    "            self.composed = transforms.Compose([\n",
    "                cropping,\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(torch.from_numpy(self.setMean).float(),\n",
    "                                     torch.from_numpy(np.array([1., 1., 1.])).float())\n",
    "            ])\n",
    "\n",
    "            self.labels = labels_array[setInd, :]\n",
    "            self.im_paths = np.array(im_paths)[setInd].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = Image.open(self.im_paths[idx])\n",
    "        y = self.labels[idx, :]\n",
    "        x = self.composed(x)\n",
    "        y = np.argmax(y)\n",
    "        y = np.int64(y)\n",
    "        return x, y, idx\n",
    "\n",
    "#磁盘，选用第一块作为基底\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#标签及图片路径，5折交叉分割文件\n",
    "# root = '/home/deeplearning/wwt/pymodel/model/skin_detect/isic2018-master/task3/labels/HAM10000/'\n",
    "# img_dir = '/home/deeplearning/wwt/pymodel/model/skin_detect/isic2018-master/task3/images/HAM10000/'\n",
    "# file = '/home/deeplearning/wwt/weight_test/pytorch_test/model_data/indices_new.pkl'\n",
    "\n",
    "\n",
    "root = '/media/scw4750/disk/test/skin_detect/isic2018-master/task3/labels/HAM10000/'\n",
    "img_dir = '/media/scw4750/disk/test/skin_detect/isic2018-master/task3/images/HAM10000/'\n",
    "file = '/media/scw4750/disk/test/skin_detect/isic2018-master/saved_model/indices_new.pkl'\n",
    "#图片路径列表\n",
    "im_paths = [os.path.join(img_dir, img) for img in os.listdir(img_dir)]\n",
    "# print(\"im_paths\", np.array(im_paths).shape)\n",
    "\n",
    "#打开标签文件，保存到字典中\n",
    "labels_dict = {}\n",
    "with open(root+'label.csv', newline='') as csvfile:\n",
    "    labels_str = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in labels_str:\n",
    "        if 'ISIC' not in row[0]:\n",
    "            continue\n",
    "        labels_dict[row[0]] = np.array(\n",
    "            [int(float(row[1])), int(float(row[2])), int(float(row[3])), int(float(row[4])),\n",
    "             int(float(row[5])), int(float(row[6])), int(float(row[7]))])\n",
    "# print(\"labels_dict:\", labels_dict)\n",
    "\n",
    "#图片id列表以及标签列表\n",
    "img_ids_list = []\n",
    "labels_list = []\n",
    "for img in im_paths:\n",
    "    id = img[img.rindex(\"/\") + 1:img.rindex(\".\")]\n",
    "    array = labels_dict.get(id)\n",
    "    img_ids_list.append(id)\n",
    "    labels_list.append(array)\n",
    "# print(\"img_ids_list:\", img_ids_list)\n",
    "# print(\"labels_list:\", labels_list)\n",
    "\n",
    "#标签数组以及计算各类所占比例\n",
    "labels_array = np.zeros([len(labels_list), 7], dtype=np.float32)\n",
    "for i in range(len(labels_list)):\n",
    "    labels_array[i, :] = labels_list[i]\n",
    "# print(\"labels_array:\", labels_array)\n",
    "# print(np.mean(labels_array, axis=0))\n",
    "\n",
    "#保存5折交叉验证的标签\n",
    "with open(file, 'rb') as f:\n",
    "    indices = pickle.load(f)\n",
    "trainIndCV = indices['trainIndCV']\n",
    "valIndCV = indices['valIndCV']\n",
    "#最终得到的最优值\n",
    "f1Best = {}\n",
    "sensBest = {}\n",
    "specBest = {}\n",
    "accBest = {}\n",
    "waccBest = {}\n",
    "aucBest = {}\n",
    "convergeTime = {}\n",
    "bestPred = {}\n",
    "target = {}\n",
    "\n",
    "#用到的几个常数\n",
    "cv = 0\n",
    "lr = 0.000025*len(numGPUs)\n",
    "lastBestInd = -1\n",
    "batchSize = 20 * len(numGPUs)\n",
    "# numBatchesTrain = int(math.floor(len(trainInd) / batchSize))\n",
    "# print(\"Train batches\", numBatchesTrain)\n",
    "start_epoch = 1\n",
    "display_step = 5\n",
    "training_steps = 150\n",
    "eval_set = 'valInd'\n",
    "\n",
    "\n",
    "def get_mean_std(dataloader):\n",
    "    \"\"\"Get mean and std by sample ratio\n",
    "    \"\"\"\n",
    "    train = iter(dataloader).next()[0]   # 一个batch的数据\n",
    "    mean = np.mean(train.numpy(), axis=(0,2,3))\n",
    "    std = np.std(train.numpy(), axis=(0,2,3))\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "print('Train')\n",
    "trainInd = trainIndCV[0]\n",
    "print(trainInd.shape)\n",
    "print('val')\n",
    "valInd = valIndCV[0]\n",
    "print(valInd.shape)\n",
    "\n",
    "#不平衡类加权方法\n",
    "indices_ham = trainInd[trainInd < 10015]\n",
    "class_weights = 1.0 / np.mean(labels_array[indices_ham, :], axis=0)\n",
    "print(\"Current class weights\", class_weights)\n",
    "\n",
    "\n",
    "#训练集准备\n",
    "trainset = ISICdataset(trainInd, im_paths, labels_array, train=True)\n",
    "#测试集准备\n",
    "valset = ISICdataset(valInd, im_paths, labels_array, train=False)\n",
    "#数据加载\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batchSize, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "train_mean, train_std = get_mean_std(trainloader)\n",
    "\n",
    "test_mean, test_std = get_mean_std(valloader)\n",
    "\n",
    "print(train_mean, train_std)\n",
    "print(test_mean,test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
