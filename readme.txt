文件夹包含以下内容：
代码部分
数据部分  /weight_test/datasets/ISIC2018/cache/task12_images_224.npy 分割数据集
       /weight_test/datasets/ISIC2018/cache/task1_masks_224.npy 分割标签
       /weight_test/datasets/ISIC2018/cache/task3_images_224.npy 图像数据集
保存模型路径 /media/scw4750/disk/wwt/2019_7_25/model_data

图像均值和方差
训练集[0.7811761，0.5264199，0.54028153] [0.13406543，0.17649162，0.1900084 ]
测试集[0.754263，0.50416595，0.5183167 ] [0.13232674，0.15433034，0.1807971 ]

历史纪录：
2019.7.25 添加该文档，准备数据集和历史代码，跑了下分割以及分类代码，现在依然可用
原始版本classify.py参数 resnet101，采用加权优化，lr = 0.0001*len(numGPUs)，batchSize = 20 * len(numGPUs)，training_steps = 150，multiCropEval = 36
数据预处理，随机裁剪，彩色变换，水平翻转，竖直翻转，标准化，均值为[0.485, 0.456, 0.406]，方差为[0.229, 0.224, 0.225]，
多尺度裁剪multiCropEval，修改最后分层为MLP

origin.py 最原始的代码，就应对了数据不均衡采用加权,resnet101
classify_no_MLP.py 没有加入MLP结构，resnet01\

调参1，学习率0.01
0.001  表现最好
0.0001
0.00001

没有采用加权优化的结果，灵敏度特别低

明天跑一下5个模型

后天跑一下加权裁剪N=9,16,25,36,49,64

外后天跑一下分割的

外外后天跑一下交叉验证的

比较一下多尺度裁剪与投票表决

SVM或者随机森林的集成

有空可以跑一下每个模型没有数据增强的结果

跑了一个250步，0.00001学习率的resnet101,36多批次裁剪模型